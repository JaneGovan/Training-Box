model_name_or_path: ./models/Qwen2.5-1.5B-Instruct
reward_model_path: ./models/Skywork-Reward-V2-Qwen3-0.6B
train_data_path: ./data/rl/grpo
output_dir: ./save_models/rl/grpo/Qwen2.5-1.5B-Instruct
device_map: auto
gradient_checkpointing: False
max_length: 512
per_device_train_batch_size: 2
gradient_accumulation_steps: 4
do_train: true
num_generations: 2
generation_batch_size: 4
## 候选回答生成方式的选择，默认use_transformers_paged和use_vllm都为false
use_transformers_paged: False
use_vllm: False

num_train_epochs: 3
save_steps: 102
learning_rate: 1.0e-5
loss_type: grpo
beta: 0.5
optim: adamw_torch
weight_decay: 0.0
fp16: true
max_grad_norm: 1.0
logging_steps: 10
preprocessing_num_workers: 16
lr_scheduler_type: cosine
trust_remote_code: true
# deepspeed: ./ds_config/ds_z3_config.json